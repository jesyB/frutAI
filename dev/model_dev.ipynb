{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0269a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencias\n",
    "\n",
    "!pip install -q torch==2.3.0+cu118 torchvision==0.18.0+cu118 torchaudio==2.3.0 --index-url https://download.pytorch.org/whl/cu118\n",
    "!pip install torch torchvision \n",
    "!pip install segment-anything timm tqdm matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d4bd23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar librerías básicas\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import timm  # EfficientNet disponible en `timm`\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96384fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIGURACIÓN DEL DISPOSITIVO\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Usando dispositivo: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83db7024",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = \"/kaggle/input/frutas-nuevas/Frutas-seleccionadas\"\n",
    "train_path = os.path.join(DATASET_PATH, \"Training\")\n",
    "val_path = os.path.join(DATASET_PATH, \"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2dae19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Definir transformaciones ---\n",
    "from torchvision import transforms\n",
    "\n",
    "from torchvision.models import EfficientNet_B3_Weights\n",
    "# definir transformaciones\n",
    "weights = EfficientNet_B3_Weights.DEFAULT\n",
    "imagenet_transforms = weights.transforms()  # ✅ define it outside the Compose\n",
    "\n",
    "# Normalización estándar de ImageNet (usada por EfficientNet)\n",
    "#imagenet_mean = [0.485, 0.456, 0.406]\n",
    "#imagenet_std = [0.229, 0.224, 0.225]\n",
    "\n",
    "# Data augmentation para entrenamiento\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize((300, 300)),\n",
    "    transforms.RandomResizedCrop(300, scale=(0.8, 1.0)),\n",
    "    transforms.RandomRotation(degrees=(0, 360)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomVerticalFlip(p=0.5),\n",
    "    transforms.RandomAffine(degrees=15, translate=(0.1, 0.1), scale=(0.9, 1.1), shear=10),\n",
    "    transforms.ColorJitter(brightness=0.3, contrast=0.3),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Validación (sin data augmentation)\n",
    "transform_val = transforms.Compose([\n",
    "    transforms.Resize((300, 300)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd32456d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---  Cargar conjunto de datos ---\n",
    "\n",
    "train_dataset = datasets.ImageFolder(os.path.join(DATASET_PATH, \"Training\"), transform=transform_train)\n",
    "val_dataset = datasets.ImageFolder(os.path.join(DATASET_PATH, \"Test\"), transform=transform_val)\n",
    "\n",
    "# ---  Crear DataLoaders ---\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\n",
    "val_loader  = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=2)\n",
    "\n",
    "# Mostrar 5 imagenes random del dataset y tamaño de carpetas Training y Test\n",
    "print(f\"Training size: {len(train_dataset)} | Test size: {len(val_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80350ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODELO + FINE-TUNING\n",
    "\n",
    "from torchvision.models import efficientnet_b3, EfficientNet_B3_Weights\n",
    "num_classes = len(train_dataset.classes)\n",
    "\n",
    "model = efficientnet_b3(weights=EfficientNet_B3_Weights.IMAGENET1K_V1)\n",
    "\n",
    "# Congelar primeras capas\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Modificar la última capa\n",
    "model.classifier[1] = nn.Sequential(\n",
    "    nn.Linear(model.classifier[1].in_features, 512),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.3),  # Regularización\n",
    "    nn.Linear(512, num_classes)\n",
    ")\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4d49ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIMIZACIÓN Y FUNCIÓN DE PÉRDIDA\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.classifier.parameters(), lr=1e-4, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0db244",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENTRENAMIENTO CON GUARDADO DEL MEJOR MODELO\n",
    "\n",
    "epochs = 5 \n",
    "best_val_acc = 0.0  # Inicializar mejor precisión en validación\n",
    "# Listas para guardar métricas\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "val_losses = []\n",
    "val_accuracies = []\n",
    "\n",
    "history = {\"train_losses\": [], \"val_losses\": [], \"train_accuracies\": [], \"val_accuracies\": []}\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    total = 0\n",
    "\n",
    "    pbar = tqdm(train_loader, desc=f\"Entrenando Epoch {epoch+1}/{epochs}\", leave=False)\n",
    "    for inputs, labels in pbar:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        running_corrects += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "        pbar.set_postfix(loss=loss.item())\n",
    "\n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc = 100 * (running_corrects / total)\n",
    "    train_losses.append(epoch_loss)\n",
    "    train_accuracies.append(epoch_acc)\n",
    "\n",
    "    # Validación\n",
    "    model.eval()\n",
    "    val_running_loss = 0.0\n",
    "    val_running_corrects = 0\n",
    "    val_total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            val_running_loss += loss.item() * inputs.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            val_running_corrects += (preds == labels).sum().item()\n",
    "            val_total += labels.size(0)\n",
    "\n",
    "    \n",
    "    val_epoch_loss = val_running_loss / val_total\n",
    "    val_epoch_acc = 100 * (val_running_corrects / val_total)\n",
    "    val_losses.append(val_epoch_loss)\n",
    "    val_accuracies.append(val_epoch_acc)\n",
    "    scheduler.step()\n",
    "\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{epochs} | \"\n",
    "          f\"Train Loss: {epoch_loss:.4f}, Train Acc: {epoch_acc:.2f}% | \"\n",
    "          f\"Val Loss: {val_epoch_loss:.4f}, Val Acc: {val_epoch_acc:.2f}%\")\n",
    "    # # Guardar el modelo si la precisión en validación mejora\n",
    "    \n",
    "    if val_epoch_acc > best_val_acc:\n",
    "        best_val_acc = val_epoch_acc\n",
    "        \n",
    "        save_dir = \"/kaggle/working/models\"\n",
    "\n",
    "        # Crear la carpeta si no existe\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "        # Ruta para guardar el modelo\n",
    "        best_model_path = os.path.join(save_dir, \"best_efficientnet_b3.pth\")\n",
    "        torch.save(model.state_dict(), best_model_path)\n",
    "        print(f\"✅ Nuevo mejor modelo guardado con {best_val_acc:.2f}% de precisión en validación.\")\n",
    "        print(f\"✅ Modelo guardado en {best_model_path}\")\n",
    "\n",
    "history[\"train_losses\"].append(epoch_loss)\n",
    "history[\"train_accuracies\"].append(epoch_acc)\n",
    "history[\"val_losses\"].append(val_epoch_loss)\n",
    "history[\"val_accuracies\"].append(val_epoch_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd613f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---  Graficar resultados ---\n",
    "plt.figure(figsize=(12,5))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(train_losses, label='Pérdida Entrenamiento')\n",
    "plt.plot(val_losses, label='Pérdida Validación')\n",
    "plt.xlabel('Época')\n",
    "plt.ylabel('Pérdida')\n",
    "plt.title('Pérdida durante Entrenamiento y Validación')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(train_accuracies, label='Precisión Entrenamiento')\n",
    "plt.plot(val_accuracies, label='Precisión Validación')\n",
    "plt.xlabel('Época')\n",
    "plt.ylabel('Precisión (%)')\n",
    "plt.title('Precisión durante Entrenamiento y Validación')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b54749",
   "metadata": {},
   "outputs": [],
   "source": [
    "##  ---------------    Matriz de Confusion ---------------\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# --- Obtener predicciones en test ---\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in val_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# --- Clasificación por clase ---\n",
    "print(classification_report(all_labels, all_preds, target_names=val_dataset.classes))\n",
    "\n",
    "# --- Matriz de confusión ---\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "plt.figure(figsize=(12,10))\n",
    "sns.heatmap(cm, annot=True, fmt='d', xticklabels=val_dataset.classes, yticklabels=val_dataset.classes, cmap='Blues')\n",
    "plt.xlabel(\"Predicho\")\n",
    "plt.ylabel(\"Real\")\n",
    "plt.title(\"Matriz de Confusión en Validación\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2b3945",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "\n",
    "train_dataset = datasets.ImageFolder(root=\"/kaggle/input/frutas-nuevas/Frutas-seleccionadas/Training\")\n",
    "print(\"📝 Orden de las clases:\", train_dataset.classes)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
