{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0269a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencias\n",
    "\n",
    "!pip install -q torch==2.3.0+cu118 torchvision==0.18.0+cu118 torchaudio==2.3.0 --index-url https://download.pytorch.org/whl/cu118\n",
    "!pip install torch torchvision \n",
    "!pip install segment-anything timm tqdm matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d4bd23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar librer√≠as b√°sicas\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import timm  # EfficientNet disponible en `timm`\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96384fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIGURACI√ìN DEL DISPOSITIVO\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Usando dispositivo: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83db7024",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = \"/kaggle/input/frutas-nuevas/Frutas-seleccionadas\"\n",
    "train_path = os.path.join(DATASET_PATH, \"Training\")\n",
    "val_path = os.path.join(DATASET_PATH, \"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2dae19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Definir transformaciones ---\n",
    "from torchvision import transforms\n",
    "\n",
    "from torchvision.models import EfficientNet_B3_Weights\n",
    "# definir transformaciones\n",
    "weights = EfficientNet_B3_Weights.DEFAULT\n",
    "imagenet_transforms = weights.transforms()  # ‚úÖ define it outside the Compose\n",
    "\n",
    "# Normalizaci√≥n est√°ndar de ImageNet (usada por EfficientNet)\n",
    "#imagenet_mean = [0.485, 0.456, 0.406]\n",
    "#imagenet_std = [0.229, 0.224, 0.225]\n",
    "\n",
    "# Data augmentation para entrenamiento\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize((300, 300)),\n",
    "    transforms.RandomResizedCrop(300, scale=(0.8, 1.0)),\n",
    "    transforms.RandomRotation(degrees=(0, 360)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomVerticalFlip(p=0.5),\n",
    "    transforms.RandomAffine(degrees=15, translate=(0.1, 0.1), scale=(0.9, 1.1), shear=10),\n",
    "    transforms.ColorJitter(brightness=0.3, contrast=0.3),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Validaci√≥n (sin data augmentation)\n",
    "transform_val = transforms.Compose([\n",
    "    transforms.Resize((300, 300)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd32456d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---  Cargar conjunto de datos ---\n",
    "\n",
    "train_dataset = datasets.ImageFolder(os.path.join(DATASET_PATH, \"Training\"), transform=transform_train)\n",
    "val_dataset = datasets.ImageFolder(os.path.join(DATASET_PATH, \"Test\"), transform=transform_val)\n",
    "\n",
    "# ---  Crear DataLoaders ---\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\n",
    "val_loader  = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=2)\n",
    "\n",
    "# Mostrar 5 imagenes random del dataset y tama√±o de carpetas Training y Test\n",
    "print(f\"Training size: {len(train_dataset)} | Test size: {len(val_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80350ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODELO + FINE-TUNING\n",
    "\n",
    "from torchvision.models import efficientnet_b3, EfficientNet_B3_Weights\n",
    "num_classes = len(train_dataset.classes)\n",
    "\n",
    "model = efficientnet_b3(weights=EfficientNet_B3_Weights.IMAGENET1K_V1)\n",
    "\n",
    "# Congelar primeras capas\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Modificar la √∫ltima capa\n",
    "model.classifier[1] = nn.Sequential(\n",
    "    nn.Linear(model.classifier[1].in_features, 512),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.3),  # Regularizaci√≥n\n",
    "    nn.Linear(512, num_classes)\n",
    ")\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4d49ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIMIZACI√ìN Y FUNCI√ìN DE P√âRDIDA\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.classifier.parameters(), lr=1e-4, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0db244",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENTRENAMIENTO CON GUARDADO DEL MEJOR MODELO\n",
    "\n",
    "epochs = 5 \n",
    "best_val_acc = 0.0  # Inicializar mejor precisi√≥n en validaci√≥n\n",
    "# Listas para guardar m√©tricas\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "val_losses = []\n",
    "val_accuracies = []\n",
    "\n",
    "history = {\"train_losses\": [], \"val_losses\": [], \"train_accuracies\": [], \"val_accuracies\": []}\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    total = 0\n",
    "\n",
    "    pbar = tqdm(train_loader, desc=f\"Entrenando Epoch {epoch+1}/{epochs}\", leave=False)\n",
    "    for inputs, labels in pbar:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        running_corrects += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "        pbar.set_postfix(loss=loss.item())\n",
    "\n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc = 100 * (running_corrects / total)\n",
    "    train_losses.append(epoch_loss)\n",
    "    train_accuracies.append(epoch_acc)\n",
    "\n",
    "    # Validaci√≥n\n",
    "    model.eval()\n",
    "    val_running_loss = 0.0\n",
    "    val_running_corrects = 0\n",
    "    val_total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            val_running_loss += loss.item() * inputs.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            val_running_corrects += (preds == labels).sum().item()\n",
    "            val_total += labels.size(0)\n",
    "\n",
    "    \n",
    "    val_epoch_loss = val_running_loss / val_total\n",
    "    val_epoch_acc = 100 * (val_running_corrects / val_total)\n",
    "    val_losses.append(val_epoch_loss)\n",
    "    val_accuracies.append(val_epoch_acc)\n",
    "    scheduler.step()\n",
    "\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{epochs} | \"\n",
    "          f\"Train Loss: {epoch_loss:.4f}, Train Acc: {epoch_acc:.2f}% | \"\n",
    "          f\"Val Loss: {val_epoch_loss:.4f}, Val Acc: {val_epoch_acc:.2f}%\")\n",
    "    # # Guardar el modelo si la precisi√≥n en validaci√≥n mejora\n",
    "    \n",
    "    if val_epoch_acc > best_val_acc:\n",
    "        best_val_acc = val_epoch_acc\n",
    "        \n",
    "        save_dir = \"/kaggle/working/models\"\n",
    "\n",
    "        # Crear la carpeta si no existe\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "        # Ruta para guardar el modelo\n",
    "        best_model_path = os.path.join(save_dir, \"best_efficientnet_b3.pth\")\n",
    "        torch.save(model.state_dict(), best_model_path)\n",
    "        print(f\"‚úÖ Nuevo mejor modelo guardado con {best_val_acc:.2f}% de precisi√≥n en validaci√≥n.\")\n",
    "        print(f\"‚úÖ Modelo guardado en {best_model_path}\")\n",
    "\n",
    "history[\"train_losses\"].append(epoch_loss)\n",
    "history[\"train_accuracies\"].append(epoch_acc)\n",
    "history[\"val_losses\"].append(val_epoch_loss)\n",
    "history[\"val_accuracies\"].append(val_epoch_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd613f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---  Graficar resultados ---\n",
    "plt.figure(figsize=(12,5))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(train_losses, label='P√©rdida Entrenamiento')\n",
    "plt.plot(val_losses, label='P√©rdida Validaci√≥n')\n",
    "plt.xlabel('√âpoca')\n",
    "plt.ylabel('P√©rdida')\n",
    "plt.title('P√©rdida durante Entrenamiento y Validaci√≥n')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(train_accuracies, label='Precisi√≥n Entrenamiento')\n",
    "plt.plot(val_accuracies, label='Precisi√≥n Validaci√≥n')\n",
    "plt.xlabel('√âpoca')\n",
    "plt.ylabel('Precisi√≥n (%)')\n",
    "plt.title('Precisi√≥n durante Entrenamiento y Validaci√≥n')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b54749",
   "metadata": {},
   "outputs": [],
   "source": [
    "##  ---------------    Matriz de Confusion ---------------\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# --- Obtener predicciones en test ---\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in val_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# --- Clasificaci√≥n por clase ---\n",
    "print(classification_report(all_labels, all_preds, target_names=val_dataset.classes))\n",
    "\n",
    "# --- Matriz de confusi√≥n ---\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "plt.figure(figsize=(12,10))\n",
    "sns.heatmap(cm, annot=True, fmt='d', xticklabels=val_dataset.classes, yticklabels=val_dataset.classes, cmap='Blues')\n",
    "plt.xlabel(\"Predicho\")\n",
    "plt.ylabel(\"Real\")\n",
    "plt.title(\"Matriz de Confusi√≥n en Validaci√≥n\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2b3945",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "\n",
    "train_dataset = datasets.ImageFolder(root=\"/kaggle/input/frutas-nuevas/Frutas-seleccionadas/Training\")\n",
    "print(\"üìù Orden de las clases:\", train_dataset.classes)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
